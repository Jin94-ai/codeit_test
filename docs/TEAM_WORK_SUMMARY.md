# 팀원별 작업 내역 요약

## 프로젝트 개요

| 항목 | 내용 |
|------|------|
| **프로젝트명** | Health Eat - AI 알약 인식 |
| **기간** | 2025.12.04 ~ 12.23 (약 3주) |
| **최종 점수** | **0.96703** (Baseline 대비 +18.7%) |
| **협업일지** | 40개 |

---

## Week 0 (12/04 ~ 12/05)

### 12/05 (금)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **김민우** | Data Engineer | EDA 작성 (80%), 클래스 불균형/어노테이션 누락 발견 | 75% |
| **김나연** | Data Engineer | EDA 노트북 작성 (ny_eda.ipynb), 데이터셋 구조 분석 | 75% |
| **김보윤** | Model Architect | 역할 분담, Git 환경 구축, 모델 서치 (YOLOv8 선정) | 75% |
| **황유민** | Experiment Lead | W&B 환경 구축, 성능 지표(mAP@[0.75:0.95]) 확인 | 75% |

**주요 발견**:
- 학습 데이터: 232개 이미지, 74 클래스
- 테스트 데이터: 843개 이미지, 196 클래스
- 클래스 불균형 심각 (1:80 비율)

---

## Week 1 (12/08 ~ 12/12)

### 12/08 (월)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | EDA 리뷰 및 통합, YOLO 변환 코드 리뷰 (Ver1 → Ver2), 프로젝트 구조 개선 | 100% |
| **김민우** | Data Engineer | EDA 발표, YOLO 데이터셋 v1/v2 구현 | 100% |
| **김나연** | Data Engineer | EDA 통합, 데이터 증강 파이프라인 정의, PyTorch Dataset 구현 | 75% |
| **김보윤** | Model Architect | 베이스라인 작성, 코드 자동화 추진 | 50% |

**핵심 결정**:
- 232개 데이터 사용 결정 (file_name 기반 필터링)
- on-the-fly 증강 방식 채택
- src/data/yolo_dataset 구조 통일

### 12/09 (화)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | 프로젝트 구조 조정, 제출 파이프라인 검토 | 50% |
| **김민우** | Data Engineer | 데이터 증강 모듈 구현, 경로 수정 | 50% |
| **김나연** | Data Engineer | 전처리 노트북 완료, 증강 모듈화 (ny_augmentation.py 등) | 75% |
| **김보윤** | Model Architect | 코드 자동화 완성, 전체 파이프라인 실행 | 75% |
| **황유민** | Experiment Lead | 실험 방향 회의 주관, W&B 팀 초대 | 25% |

**문제 발견**:
- Test 데이터 경로 누락
- CSV 제출 형식 불일치
- 환경 차이 (Windows/WSL/Ubuntu)

### 12/10 (수)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | category_id 매핑 오류 해결, W&B 통합, 파이프라인 안정성 개선 | 75% |
| **김민우** | Data Engineer | AIHub 추가 데이터셋 EDA, 클래스 필터링 로직 구현 | 75% |
| **김나연** | Data Engineer | 모듈화 완료, AIHub TL_3 데이터셋 확보 (1,491개 이미지) | 75% |
| **황유민** | Experiment Lead | 팀 미팅, 실험 추적 시스템 논의 | - |

**핵심 해결**:
- category_id 매핑 오류 발견 (0점 원인)
- class_mapping.json 생성으로 해결
- NMS 타임아웃: WSL2 /mnt/c/ 경로 병목 확인

### 12/11 (목)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | AIHub 콤보 데이터 통합 시도, 성능 하락 발견 | 50% |
| **김민우** | Data Engineer | 추가 데이터셋 경로 정리, 증강 모듈 개선 | 75% |
| **김나연** | Data Engineer | 데이터셋 통합 지원 | 75% |
| **김보윤** | Model Architect | 자동화 파이프라인 개선 | 75% |
| **황유민** | Experiment Lead | 실험 로그 관리 | - |

**중대 발견**:
- AIHub 콤보 데이터 추가 시 성능 20% 하락
- 원인: 미라벨링 객체가 "배경"으로 학습됨

### 12/12 (금)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | 콤보 데이터 폐기, 싱글 데이터 분석, baseline 원상복구 | 75% |
| **김민우** | Data Engineer | YOLO11m 모델 추가, 시드 고정 | 100% |
| **김나연** | Data Engineer | 증강 모듈 개발 | 75% |
| **김보윤** | Model Architect | 모델 실험, 체크포인트 관리 | 75% |
| **황유민** | Experiment Lead | 실험 스케줄링 | - |

**첫 Kaggle 제출**: 0.815 (Baseline)

---

## Week 2 (12/15 ~ 12/18)

### 12/15 (월)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **김민우** | Data Engineer | 증강 모듈 개별 브랜치용 | 75% |
| **김나연** | Data Engineer | 증강 모듈 개발 | 75% |

### 12/16 (화)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | bbox 보정 시도 및 폐기, 논문 조사 (6개 분야), baseline 개선 | 100% |
| **김민우** | Data Engineer | 증강 적용 | 75% |
| **김나연** | Data Engineer | 데이터 처리 | 75% |

**논문 조사 결과**:
- Mosaic/Mixup > loss weighting (클래스 불균형)
- 50%+ missing rate → 성능 급락 확인
- Orthogonal Mapping으로 mAP 4% 향상 가능

### 12/17 (수)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **김민우** | Data Engineer | 실험 스케줄링, 추가 데이터셋 추출 모듈 | 75% |
| **김나연** | Data Engineer | 데이터 처리 지원 | 75% |

### 12/18 (목) - **핵심 전환점**

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | **2-Stage Pipeline 설계 및 구현**, Detector/Classifier 학습, 0.96 달성 | 100% |
| **김민우** | Data Engineer | 데이터셋 지원 | 75% |
| **김나연** | Data Engineer | 데이터셋 지원 | 75% |

**2-Stage Pipeline 아키텍처**:
```
Stage 1: YOLO11m Detector (단일 클래스 "Pill")
    └── AIHub + Kaggle 데이터 (7,000개)
Stage 2: ConvNeXt Classifier (74개 클래스)
    └── 크롭 이미지 분류
```

**점수 변화**:
| Submission | Score | 내용 |
|------------|-------|------|
| #3 | 0.920 | 2-Stage (YOLO + YOLO-cls) |
| #4 | 0.963 | 2-Stage (YOLO + ConvNeXt) |

---

## Week 3 (12/19 ~ 12/22)

### 12/19 (금)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | AIHub bbox 추출 로직 수정, 데이터 정제, **0.96703 달성** | 100% |

**핵심 수정**:
- 기존: 74개 타겟 클래스 폴더만 스캔 → bbox 누락
- 수정: 모든 K-code 폴더 스캔하여 모든 bbox 수집
- 결과: 0.965 → **0.96703** (Best Score)

### 12/22 (월)

| 팀원 | 역할 | 작업 내용 | 완료도 |
|------|------|----------|--------|
| **이진석** | Leader | imgsz 1280 + TTA 실험 (실패), 저장소 정리, 문서화 | 100% |

**추가 실험 결과**:
| Submission | Score | 내용 |
|------------|-------|------|
| #7 | 0.713 | imgsz 1280 (성능 저하) |
| #8 | 0.533 | imgsz 1280 + TTA (성능 저하) |

**결론**: 기존 640 모델 유지

---

## 팀원별 총 기여 요약

### 이진석 (Leader / Integration)
- **핵심 성과**: 2-Stage Pipeline 설계 및 구현
- 프로젝트 구조 설계 및 유지
- AIHub 데이터 추출 로직 개선 (Best Score 핵심 기여)
- 코드 리뷰 및 통합, 기술적 의사결정 지원
- 논문 조사 및 실험 로그 관리
- **협업일지**: 12개

### 김민우 (Data Engineer)
- 데이터 EDA 수행 및 발표
- YOLO 데이터셋 변환 모듈 구현 (Ver1/Ver2)
- 데이터 증강 모듈 개발
- AIHub 추가 데이터셋 탐색 및 필터링
- **협업일지**: 12개

### 김나연 (Data Engineer)
- 데이터 EDA 노트북 작성 (ny_eda.ipynb)
- 데이터 전처리 모듈화 (ny_augmentation.py, ny_dataset.py)
- AIHub TL_3 데이터셋 확보 (1,491개 이미지)
- PyTorch Dataset 클래스 구현
- **협업일지**: 11개

### 김보윤 (Model Architect)
- YOLO 베이스라인 모델 설계
- 학습 파이프라인 자동화
- 시드 고정 및 체크포인트 관리
- Colab 학습 환경 구축
- **협업일지**: 7개

### 황유민 (Experiment Lead)
- W&B 실험 추적 시스템 구축
- 실험 방향 회의 주관
- 실험 로그 및 스케줄링 관리
- 성능 지표 정의 및 모니터링
- **협업일지**: 5개

---

## 점수 개선 히스토리

```
0.815 ─────────────────────────────────────────── Baseline
  │
  │  ↓ End-to-end 196 클래스 (실패)
  │
0.690 ───────────────────────────────────────────
  │
  │  ↑ 2-Stage Pipeline 도입 (+0.230)
  │
0.920 ───────────────────────────────────────────
  │
  │  ↑ ConvNeXt Classifier (+0.043)
  │
0.963 ───────────────────────────────────────────
  │
  │  ↑ bbox 추출 수정 (+0.004)
  │
0.967 ────────────────────────────────────────── Best Score
```

---

## 핵심 성공 요인

1. **2-Stage 분리**: Detection과 Classification 독립 최적화
2. **AIHub 데이터 활용**: bbox 어노테이션 품질 우수
3. **데이터 필터링**: 테스트 환경과 유사한 3~4개 bbox만 사용
4. **ConvNeXt 도입**: ImageNet pretrained → 강력한 분류 성능
5. **빠른 실험 및 피드백**: 실패 원인 분석 후 방향 전환

---

## 결론

3주간 40개의 협업일지를 통해 체계적으로 작업을 기록하고, 팀원 간 역할 분담을 명확히 하여 **Baseline 0.815에서 0.96703까지 +18.7% 개선** 달성.

핵심은 **End-to-end 접근법의 한계를 인식**하고 **2-Stage Pipeline으로 전환**한 것이며, 데이터 품질 개선(AIHub bbox 추출 수정)이 최종 성능 향상의 결정적 요인이었음.
