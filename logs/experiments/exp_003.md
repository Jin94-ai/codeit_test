# Experiment 003

## 실험 정보
- **날짜**: 2024-12-14
- **담당**: JIN
- **목적**: 데이터 불균형 해소를 통한 성능 개선 (Pseudo-labeling, Oversampling)

## 배경
- 기존 데이터: 186개 이미지 (라벨 있는 것만)
- 클래스 불균형 심각: 최대 242개 vs 최소 1개 (242배 차이)
- 라벨 없는 이미지 295개 패턴 존재

## 실험 A: Pseudo-labeling Only

### 방법
- 학습된 모델로 라벨 없는 이미지에 예측 라벨 생성
- Confidence threshold: 0.7 (높은 신뢰도만 사용)
- 419개 이미지 추가 (총 605개)

### 결과
| 항목 | 기본 | Pseudo-labeling |
|------|------|-----------------|
| 총 예측 수 | 2,464 | 1,826 (-26%) |
| 고유 카테고리 | 42 | 40 (-2) |
| Kaggle Score | 0.65 | **하락** |

### 분석
- Confidence는 높아졌으나 (0.94~0.99) Recall 크게 하락
- 4개 클래스 완전 누락: 19606, 25437, 28762, 33008
- **문제**: 모델이 이미 잘 아는 클래스만 강화됨, 부족한 클래스는 여전히 부족

---

## 실험 B: Pseudo-labeling + Oversampling

### 방법
1. Pseudo-labeling (위와 동일)
2. Oversampling: 20개 미만 클래스의 이미지/라벨 복제
   - 부족한 클래스 28개 대상
   - 최소 20개까지 복제

### 클래스 분포 변화 (부족한 클래스 TOP 10)
| 클래스 | 원본 | Oversampling 후 |
|--------|------|-----------------|
| 31884 | 1 | 20 |
| 29450 | 2 | 20 |
| 27925 | 2 | 20 |
| 16550 | 2 | 20 |
| 33207 | 2 | 20 |
| 3742 | 2 | 20 |
| 13394 | 2 | 20 |
| 12080 | 2 | 20 |
| 34596 | 2 | 20 |
| 27776 | 2 | 20 |

### 결과
| 항목 | 기본 | Pseudo Only | Pseudo + OS |
|------|------|-------------|-------------|
| 총 예측 수 | 2,464 | 1,826 | 1,908 |
| 고유 카테고리 | 42 | 40 | **46** |
| Kaggle Score | 0.65 | 하락 | **0.66** |

### 분석
- 카테고리 수 40 → 46개로 증가 (기본 42개보다도 많음!)
- 누락됐던 6개 클래스 복구: 12080, 19606, 27925, 28762, 33207, 4542
- 여전히 2개 클래스 누락: 25437, 33008
- Oversampling이 희귀 클래스 탐지에 효과적

---

## 결론

### 효과 있는 방법
- **Oversampling**: 희귀 클래스 탐지 개선에 효과적 (+0.01)

### 효과 없거나 역효과
- **Pseudo-labeling 단독**: 데이터 불균형 악화, Recall 하락

### 한계점
- Pseudo-labeling은 모델이 모르는 클래스를 보강할 수 없음
- Oversampling은 동일 이미지 복제라 다양성 한계
- 총 예측 수(Recall)가 여전히 기본 대비 낮음

---

## 다음 단계
1. **AIHub 단일 데이터 추가** (다운로드 중)
   - 클래스당 100개씩 실제 라벨 데이터 추가
   - 데이터 다양성 + 불균형 해소 동시 해결 기대

2. **추가 실험 아이디어**
   - Mosaic/Mixup/Copy-paste augmentation 강화
   - 더 큰 모델 (YOLOv8s → YOLOv8m)
   - Learning rate 및 epoch 조정
