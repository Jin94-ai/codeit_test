# Experiment 007: 최종 베스트 모델 (0.96703)

## 개요

| 항목 | 내용 |
|------|------|
| 실험 ID | exp_007 |
| 날짜 | 2025-12-19 |
| 담당자 | 이진석 |
| 목표 | 2-Stage Pipeline 최적화 |
| 결과 | **성공 (0.96703)** |

---

## 가설

1. AIHub 데이터에서 **모든 알약의 bbox**를 추출하면 Detector 성능이 향상될 것
2. 3~4개 bbox 이미지만 사용하면 테스트 환경과 유사해져 일반화 성능이 향상될 것
3. ConvNeXt가 YOLO-cls보다 분류 성능이 좋을 것

---

## 실험 설정

### 데이터 전처리

#### 1. AIHub 데이터 추출 수정 (핵심)

**Before (0.963)**:
```python
# 타겟 74개 클래스 폴더만 스캔
for k_code in TARGET_K_CODES:
    for json_path in k_code_folder.glob("*.json"):
        # bbox 추출
```

**After (0.96703)**:
```python
# 모든 K-code 폴더 스캔
for json_path in all_json_files:
    # 모든 bbox 수집 (Detector는 단일 클래스)
    img_data['bboxes'].append(bbox)

    # 이미지 선택은 타겟 클래스 기준
    if k_code in TARGET_K_CODES:
        img_data['k_codes'].add(k_code)
```

#### 2. 데이터 필터링

```python
# cleanup_detector_data.py
BBOX_COUNT_RANGE = (3, 4)  # 3~4개 bbox만
IOU_THRESHOLD = 0.7        # 중복 제거
MIN_BBOX_SIZE = 50         # 최소 크기
MAX_BBOX_SIZE = 500        # 최대 크기
ASPECT_RATIO_RANGE = (0.3, 3.0)  # 비율 제한
```

#### 3. 데이터 분포

| bbox 개수 | 이미지 수 | 비율 |
|-----------|----------|------|
| 4개 | ~5,833 | 83% |
| 3개 | ~1,167 | 17% |
| **합계** | **~7,000** | 100% |

### 모델 설정

#### Stage 1: YOLO11m Detector

```python
CONFIG = {
    "model": "yolo11m.pt",
    "data": "data/yolo/pills.yaml",
    "epochs": 50,
    "imgsz": 640,
    "batch": 8,
    "patience": 15,
    "conf": 0.3,
    "iou": 0.5,
    "project": "runs/detect",
    "name": "yolo11m_detector",
}
```

#### Stage 2: ConvNeXt Classifier

```python
CONFIG = {
    "model_name": "convnext_tiny",
    "pretrained": True,
    "epochs": 50,
    "batch_size": 32,
    "lr": 1e-4,
    "weight_decay": 0.01,
    "img_size": 224,
    "val_split": 0.1,
    "patience": 10,
}
```

### 추론 설정

```python
# submit_v2.py
detector_conf = 0.05    # 낮춰서 recall 확보
classifier_conf = 0.3
detector_iou = 0.5
agnostic_nms = True
max_det = 4
```

---

## 실험 결과

### Stage 1: Detector 학습 결과

| Metric | 값 |
|--------|-----|
| mAP50 | 0.995 |
| mAP50-95 | 0.85 |
| Precision | 0.99 |
| Recall | 0.99 |

### Stage 2: Classifier 학습 결과

| Metric | 값 |
|--------|-----|
| Val Accuracy | 98.5% |
| Early Stop | Epoch 21 |

### Kaggle 제출 결과

| Submission | Score | 변경사항 |
|------------|-------|----------|
| #4 | 0.963 | 기존 bbox 추출 |
| #5 | 0.965 | AIHub 추가 |
| **#6** | **0.96703** | **bbox 추출 수정 + 정제** |

---

## 분석

### 성공 요인

1. **bbox 누락 해결**
   - 이전: 타겟 클래스 폴더만 스캔 → 일부 bbox 누락
   - 이후: 모든 폴더 스캔 → 이미지 내 모든 알약 bbox 포함
   - Detector가 모든 알약 위치 학습 가능

2. **데이터 품질 향상**
   - 3~4개 bbox 이미지만 사용 → 테스트 환경과 유사
   - 중복/비정상 bbox 제거 → 노이즈 감소

3. **ConvNeXt 분류 성능**
   - YOLO-cls 대비 더 정확한 분류
   - ImageNet pretrained → 강력한 feature extraction

### 한계점

1. **mAP@[0.75:0.95] 기준**
   - bbox 경계 정밀도가 매우 중요
   - IoU 0.75~0.95에서 정확히 맞아야 함

2. **추가 실험 실패**
   - imgsz 1280: 0.713 (성능 저하)
   - TTA: 0.533 (성능 저하)
   - 원인: 학습/추론 설정 불일치 추정

---

## 점수 개선 히스토리

| 버전 | Score | 주요 변경 | 개선폭 |
|------|-------|----------|--------|
| Baseline | 0.815 | End-to-end YOLO | - |
| v1 | 0.690 | 196 클래스 시도 | -0.125 |
| v2 | 0.920 | 2-Stage 도입 | +0.230 |
| v3 | 0.963 | ConvNeXt | +0.043 |
| v4 | 0.965 | AIHub 추가 | +0.002 |
| **v5** | **0.96703** | **bbox 수정** | **+0.002** |

**총 개선**: 0.815 → 0.96703 (**+18.7%**)

---

## 재현 코드

```bash
# 1. 데이터 추출
python src/data/aihub/extract_for_detector.py

# 2. YOLO 포맷 변환
python -m src.data.yolo_dataset.yolo_export_detector

# 3. 데이터 정제
python src/data/cleanup_detector_data.py

# 4. Detector 학습
python src/models/yolo11m_detector.py

# 5. Classifier 학습
python src/models/convnext_classifier.py

# 6. 추론
python -m src.inference.submit_v2
```

---

## 결론

- AIHub 데이터 추출 로직 수정이 **핵심 개선 포인트**
- 모든 알약 bbox를 포함하여 Detector 학습 품질 향상
- 0.96703 달성 (Baseline 대비 +18.7%)

---

## 태그

`#2-stage` `#detector` `#classifier` `#convnext` `#aihub` `#성공` `#최종`
