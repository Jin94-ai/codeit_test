# Experiment 005

## 실험 정보
- **날짜**: 2025-12-16
- **담당**: JIN
- **목적**: YOLOv11 + 데이터셋 전략 논문 조사
- **결과**: Single 데이터 사용 결정, baseline 개선 방향 도출

---

## 1. YOLOv11 아키텍처 개선점

| 특징 | 설명 | 참고 |
|------|------|------|
| C3K2 Block | 3×3 커널로 효율적 연산, 파라미터 감소 | [arXiv](https://arxiv.org/html/2410.17725v1) |
| C2PSA | Parallel Spatial Attention - 작은/밀집 객체 탐지 향상 | [Medium](https://medium.com/@nikhil-rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-accuracy-2dbe2d376f71) |
| SPPF | Spatial Pyramid Pooling Fast | [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/10/yolov11/) |
| NMS-Free | Non-Maximum Suppression 제거로 추론 속도 향상 | |
| Size-specific 최적화 | YOLOv11-small 등 객체 크기별 최적화 가능 | [arXiv](https://arxiv.org/html/2412.14790v2) |

---

## 2. Domain Adaptation (배경 차이 문제)

### 관련 논문

| 논문 | 핵심 기법 | 링크 |
|------|----------|------|
| SF-YOLO | Teacher-Student + 타겟 도메인 augmentation | [arXiv](https://arxiv.org/abs/2409.16538) |
| HMDA-YOLO | Multi-scale 픽셀 레벨 adaptation | [PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431383/) |
| ATDA-YOLO | Attention 기반 도메인 적응 | [Springer](https://link.springer.com/chapter/10.1007/978-981-96-6594-5_22) |

---

## 3. Class Imbalance (클래스 불균형)

### 핵심 발견
- **Mosaic/Mixup이 YOLO에서 가장 효과적**
- Loss weighting은 YOLO에서 오히려 역효과

### 관련 논문

| 논문 | 핵심 | 링크 |
|------|------|------|
| Class Imbalance Diagnosis | Mosaic/Mixup > loss weighting | [arXiv](https://arxiv.org/html/2403.07113v1) |
| Weighted Dataloader | 클래스별 샘플링 가중치 | [Tutorial](https://y-t-g.github.io/tutorials/yolo-class-balancing/) |
| SOM (Small Object Multiplication) | 소수 클래스 객체 복사 augmentation | [MDPI](https://www.mdpi.com/2504-446x/8/8/400) |

---

## 4. Missing Labels 문제 (Combo 데이터)

### 문제 정의
- Combo 이미지: 4개 알약 중 1개만 라벨링
- 나머지 3개가 "배경"으로 학습 → 모델 혼란

### 정량적 영향
```
Missing Rate 0~40%: 성능 소폭 감소
Missing Rate 50%+: 성능 급격히 하락
Missing Rate 70%+: YOLO가 약지도학습보다 못함

Combo 이미지 = 75% missing rate → 매우 위험!
```

### 관련 논문

| 논문 | 핵심 | 링크 |
|------|------|------|
| Background Recalibration Loss | 미라벨링 객체로 인한 혼란 해결 | [IEEE](https://ieeexplore.ieee.org/document/9053738/) |
| Object Detection as PU Problem | 라벨 없음 ≠ 배경 가정 제거 | [arXiv](https://arxiv.org/abs/2002.04672) |
| Missing Labels in OD (CVPR) | Missing rate별 성능 분석 | [CVPR](https://openaccess.thecvf.com/content_CVPRW_2019/papers/Weakly%20Supervised%20Learning%20for%20Real-World%20Computer%20Vision%20Applications/Xu_Missing_Labels_in_Object_Detection_CVPRW_2019_paper.pdf) |

---

## 5. 결론: 데이터셋 전략

### Single vs Combo

| 옵션 | 장점 | 단점 | 결정 |
|------|------|------|------|
| Combo (75% missing) | 배경 다양성 | 심각한 혼란 | ❌ 비권장 |
| Single (다양한 배경) | 완전한 라벨링 | 배경 다양성 확보 필요 | ✅ 채택 |

### 최종 결정
1. **Single 데이터 사용**
2. 배경 다양성은 augmentation으로 보완
3. Mosaic/Mixup/Copy-paste 적극 활용

---

## 6. Fine-Grained Classification 기법

### 조사한 기법

| 기법 | 효과 | 구현 |
|------|------|------|
| Orthogonal Mapping | mAP 4%↑ | `OrthogonalClassifier` |
| Class Center Loss | 클래스 분리 명확화 | `ClassCenterLoss` |
| ICE Loss | top-k 혼동 방지 | `ICELoss` |

### 구현 완료 (`src/models/classification_losses.py`)

```python
from src.models.classification_losses import (
    OrthogonalClassifier,  # FC 헤드 대체
    ClassCenterLoss,       # 보조 Loss
    ICELoss,               # CE 대체
    FineGrainedLoss,       # 통합 (Center + ICE)
)
```

### 적용 우선순위

```
1단계: ICE Loss만 (가장 쉬움)
   ↓
2단계: Center + ICE (FineGrainedLoss)
   ↓
3단계: OM + Center + ICE (전체)
```

---

## 7. Baseline 개선 적용

### 변경 사항 (`baseline.py`)

| 항목 | Before | After | 근거 |
|------|--------|-------|------|
| epochs | 50 | 100 | 충분한 학습 |
| batch | 8 | 16 | 안정적 학습 |
| mixup | 0.2 | 0.5 | Class Imbalance 논문 |
| copy_paste | 0.1 | 0.3 | SOM 논문 |
| hsv_h | 0.02 | 0.03 | Domain Randomization |
| hsv_s | 0.8 | 0.9 | Domain Randomization |
| hsv_v | 0.5 | 0.6 | Domain Randomization |
| cls | 1.5 | 2.0 | Fine-Grained 분류 |
| label_smoothing | 0.1 | 0.15 | 유사 클래스 혼동↓ |
| flipud | - | 0.5 | 추가 augmentation |

### 최종 설정

```python
model.train(
    epochs=100,
    batch=16,
    # Domain Randomization
    hsv_h=0.03, hsv_s=0.9, hsv_v=0.6,
    # Class Imbalance
    mosaic=1.0, mixup=0.5, copy_paste=0.3,
    # Fine-Grained Classification
    cls=2.0, label_smoothing=0.15,
    # 기타
    flipud=0.5, fliplr=0.5,
)
```

---

## 참고 링크 모음

### YOLOv11
- https://arxiv.org/html/2410.17725v1
- https://www.analyticsvidhya.com/blog/2024/10/yolov11/
- https://arxiv.org/html/2412.14790v2

### Domain Adaptation
- https://arxiv.org/abs/2409.16538
- https://pmc.ncbi.nlm.nih.gov/articles/PMC12431383/

### Class Imbalance
- https://arxiv.org/html/2403.07113v1
- https://y-t-g.github.io/tutorials/yolo-class-balancing/

### Missing Labels
- https://arxiv.org/abs/2002.05274
- https://arxiv.org/abs/2002.04672
