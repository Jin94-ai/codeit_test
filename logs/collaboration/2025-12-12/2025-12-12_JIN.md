# Daily 협업일지

### [1] 오늘 날짜 / 이름 / 팀명

- 날짜: 2025-12-12
- 이름: 이진석 (JIN)
- 팀명: 코드잇 8팀

---

### [2] 오늘 맡은 역할 및 구체적인 작업 내용

✍️ 답변:

Leader & Integration Specialist 역할:

1. **AIHub 콤보 데이터 성능 하락 원인 분석 완료**
   - 콤보 이미지의 "미라벨링 객체" 문제 확인
   - TARGET_CLASSES 외 알약이 배경으로 학습되는 현상 파악

2. **콤보 데이터 폐기 및 싱글 데이터 전환 결정**
   - 콤보 데이터 관련 스크립트 삭제
   - 다운로드된 AIHub 데이터 정리

3. **싱글 데이터 분석 스크립트 개발**
   - config.py: TARGET_CLASSES 설정 파일
   - analyze_annotations.py: TL ZIP 파일 분석 (압축 해제 없이)
   - integrate_single.py: 싱글 데이터 통합용 (미사용)

4. **TL 라벨링 데이터 분석 완료**
   - TL_1~81 ZIP 파일 분석
   - 55/56개 TARGET_CLASSES 발견 (41767만 미발견)
   - 32개 TS 폴더에 분산되어 있음 확인

5. **baseline.py 원상복구**
   - epochs=50, augmentation 기본값으로 복원

---

### [3] 오늘 작업 완료도 체크 (하나만 체크)

- [ ]  🔴 0% (시작 못함)
- [ ]  🟠 25% (시작은 했지만 진척 없음)
- [ ]  🟡 50% (진행 중, 절반 이하)
- [x]  🔵 75% (거의 완료됨)
- [ ]  🟢 100% (완료 및 점검까지 완료)

📌 간단한 근거:

- ✅ 성능 하락 원인 분석 완료
- ✅ 콤보 데이터 폐기 결정 및 정리
- ✅ 싱글 데이터 분석 스크립트 완성
- ✅ TL 라벨링 데이터 분석 완료 (55/56 클래스 확인)
- ⚠️ 싱글 이미지 다운로드 미진행 (용량 문제: ~1TB)

---

### [4] 오늘 협업 중 제안하거나 피드백한 내용이 있다면?

✍️ 답변:

1. **AIHub 데이터 사용 방향 전환 제안**
   - 콤보 → 싱글 데이터로 전환 결정
   - 이유: 싱글 이미지는 미라벨링 객체 문제 없음

2. **용량 문제 해결 방안 논의**
   - 32개 TS 폴더 전체 다운로드 시 ~1TB
   - 선택적 다운로드 또는 대안 필요

3. **모델 향상 대안 방안 제시**
   - 모델 업그레이드 (yolov8n → yolov8s/m)
   - Data Augmentation 강화
   - 해상도 증가 (640 → 1024)
   - TTA, 앙상블 등

---

### [5] 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점은?

✍️ 답변:

**핵심 교훈:**

1. **콤보 데이터 실패 원인 확정**
   ```
   콤보 이미지에 알약 A, B, C, D가 있고
   A만 TARGET_CLASS인 경우
   → B, C, D는 annotation 없음
   → 모델은 B, C, D를 "배경"으로 학습
   → 테스트 시 유사한 알약을 배경으로 오탐
   ```

2. **데이터 품질 > 데이터 양**
   - 잘못된 데이터 추가는 성능을 오히려 저하시킴
   - 외부 데이터 통합 시 라벨링 완전성 확인 필수

3. **싱글 데이터 분석 결과**
   - 55/56 클래스 AIHub에서 확보 가능
   - 단, 32개 TS 폴더에 분산 (~1TB)
   - 각 클래스는 1개 TL에만 존재 (중복 없음)

**문제점:**
- 저장 공간 부족 (<100GB) vs 필요 용량 (~1TB)
- aihubshell로도 개별 이미지 선택 다운로드 불가 (ZIP 단위)

---

### [6] 일정 지연이나 협업 중 어려웠던 점이 있다면?

✍️ 답변:

1. **예상치 못한 성능 하락으로 일정 지연**
   - 데이터 통합이 성능 향상으로 이어질 것으로 예상
   - 실제로는 하락 → 원인 분석 및 방향 전환에 하루 소요

2. **대용량 데이터 접근 한계**
   - AIHub 데이터 구조상 선택적 다운로드 어려움
   - 로컬 저장 공간 제약

---

### [7] 오늘 발표 준비나 커뮤니케이션에서 기여한 부분은?

✍️ 답변:

1. **실험 실패 원인 문서화**
   - 콤보 데이터 사용 시 성능 하락 원인 정리
   - 향후 유사 시도 시 참고 가능하도록 기록

2. **대안 방안 정리 및 공유**
   - AIHub 외 모델 향상 방법 8가지 정리
   - 우선순위 및 난이도별 분류

---

### [8] 내일 목표 / 할 일

✍️ 답변:

1. **Competition 데이터 클래스 분포 분석**
   - 현재 데이터의 클래스별 샘플 수 확인
   - 불균형 정도 파악

2. **모델 향상 방안 적용 검토**
   - 모델 업그레이드 (n → s/m)
   - Augmentation 강화
   - 해상도 증가

3. **부분적 AIHub 보강 가능성 검토**
   - 부족한 클래스만 선별적으로 보강
   - 용량 최소화하여 다운로드 가능 범위 확인

---
