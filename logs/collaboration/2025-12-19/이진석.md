# 협업 일지 - 2025-12-19

## 작성자
이진석 (Leader / Integration)

---

## 최종 모델 결과 요약

| Metric | Score |
|--------|-------|
| **Kaggle Score** | **0.96703** |
| 평가 기준 | mAP@[0.75:0.95] |
| Baseline 대비 개선 | +18.7% (0.815 → 0.967) |

---

## 모델 아키텍처: 2-Stage Pipeline

```
┌─────────────────────────────────────────────────────────────┐
│                    2-Stage Pipeline                         │
├─────────────────────────────────────────────────────────────┤
│  Stage 1: YOLO11m Detector                                  │
│  ├── Input: 이미지 (1280x960)                               │
│  ├── Output: Bounding Boxes + Confidence                    │
│  ├── Task: 알약 위치 검출 (Single class: "Pill")            │
│  └── 모델: runs/detect/yolo11m_detector/weights/best.pt     │
├─────────────────────────────────────────────────────────────┤
│  Stage 2: ConvNeXt Classifier                               │
│  ├── Input: 크롭된 알약 이미지 (224x224)                    │
│  ├── Output: K-code + Confidence                            │
│  ├── Task: 알약 종류 분류 (74 classes)                      │
│  └── 모델: runs/classify/convnext/best.pt                   │
└─────────────────────────────────────────────────────────────┘
```

### 왜 2-Stage인가?

1. **데이터 한계 극복**: 학습 데이터(74종) vs 테스트 데이터(196종) 클래스 불일치
2. **일반화 성능**: Detector는 "알약"만 검출 → 새로운 클래스에도 대응 가능
3. **모듈화**: 각 Stage 독립적 개선 가능

---

## 데이터 전처리 과정

### 1. 데이터 소스

| 소스 | 이미지 수 | 용도 |
|------|----------|------|
| Kaggle 학습 데이터 | 232개 | Classifier 학습 |
| AIHub 의약품 데이터 | ~7,000개 | Detector 학습 |

### 2. AIHub 데이터 추출 (`extract_for_detector.py`)

#### 핵심 수정사항 (0.963 → 0.96703 개선 원인)

**문제**: 기존 코드는 74개 타겟 클래스 폴더만 스캔 → 이미지에 다른 클래스 알약이 있으면 bbox 누락

**예시**:
- 이미지에 알약 4개 존재
- 그 중 2개만 타겟 클래스 → 2개 bbox만 추출
- 실제로는 4개 bbox 모두 필요 (Detector는 단일 클래스)

**해결**:
```python
# 모든 K-code 폴더 스캔하여 bbox 수집
for json_path in all_json_files:
    # bbox는 모든 K-code에서 수집
    img_data['bboxes'].append(bbox)

    # 이미지 선택은 타겟 클래스 기준
    if k_code in TARGET_K_CODES:
        img_data['k_codes'].add(k_code)
```

### 3. 데이터 필터링 (`cleanup_detector_data.py`)

| 필터 | 기준 | 이유 |
|------|------|------|
| bbox 개수 | 3~4개만 | 테스트 이미지가 3~4개 알약 |
| IoU 임계값 | 0.7 | 중복 bbox 제거 |
| bbox 크기 | 50x50 ~ 500x500 | 너무 작거나 큰 bbox 제외 |
| bbox 비율 | 0.3~3.0 | 비정상적인 형태 제외 |

### 4. 최종 데이터 구성

```
4개 bbox 이미지: ~5,833개 (우선)
3개 bbox 이미지: ~1,167개 (보충)
비율: 5:1
총 학습 데이터: ~7,000개
```

---

## 모델 학습 설정

### Stage 1: YOLO11m Detector

```python
CONFIG = {
    "model": "yolo11m.pt",
    "epochs": 50,
    "imgsz": 640,
    "batch": 8,
    "patience": 15,
    "conf": 0.3,
    "iou": 0.5,
}
```

**학습 결과**:
| Metric | 값 |
|--------|-----|
| mAP50 | 0.995 |
| mAP50-95 | 0.85 |
| Precision | 0.99 |
| Recall | 0.99 |

### Stage 2: ConvNeXt Classifier

```python
CONFIG = {
    "model_name": "convnext_tiny",
    "epochs": 50,
    "batch_size": 32,
    "lr": 1e-4,
    "img_size": 224,
    "patience": 10,
}
```

**학습 결과**:
| Metric | 값 |
|--------|-----|
| Val Accuracy | 98.5% |
| Early Stop | Epoch 21 |

---

## 추론 파이프라인 설정

```python
# submit_v2.py 최적 설정
detector_conf = 0.05    # 낮춰서 recall 확보
classifier_conf = 0.3   # 분류 신뢰도
detector_iou = 0.5      # NMS 임계값
agnostic_nms = True     # 클래스 무관 NMS
max_det = 4             # 이미지당 최대 검출 수
```

---

## 점수 개선 히스토리

| Submission | Score | 주요 변경 |
|------------|-------|----------|
| #1 | 0.815 | Baseline (End-to-end YOLO) |
| #2 | 0.690 | End-to-end 196 클래스 시도 |
| #3 | 0.920 | 2-Stage (YOLO + YOLO-cls) |
| #4 | 0.963 | 2-Stage (YOLO + ConvNeXt) |
| #5 | 0.965 | AIHub 데이터 추가 |
| **#6** | **0.96703** | **AIHub bbox 추출 수정 + 데이터 정제** |

---

## 재현 방법

### 1. 데이터 준비

```bash
# AIHub 데이터 추출 (타겟 74 클래스, 모든 bbox)
python src/data/aihub/extract_for_detector.py

# YOLO 포맷 변환
python -m src.data.yolo_dataset.yolo_export_detector

# 데이터 정제 (3~4개 bbox만)
python src/data/cleanup_detector_data.py
```

### 2. 모델 학습

```bash
# Stage 1: Detector
python src/models/yolo11m_detector.py

# Stage 2: Classifier
python src/models/convnext_classifier.py
```

### 3. 추론 및 제출

```bash
# Kaggle 제출 파일 생성
python -m src.inference.submit_v2

# 출력: submission_N.csv
```

---

## 핵심 인사이트

### 성공 요인

1. **2-Stage 분리**: Detection과 Classification 독립 최적화
2. **AIHub 데이터 활용**: bbox 어노테이션 품질 우수
3. **bbox 추출 로직 수정**: 모든 알약 bbox 포함
4. **데이터 필터링**: 테스트 환경과 유사한 3~4개 bbox 이미지만 사용

### 한계점

1. **mAP@[0.75:0.95] 기준**: bbox 정밀도가 매우 중요
2. **다른 팀 0.99 달성**: 추가 개선 여지 존재
3. **imgsz 1280 실험 실패**: 학습/추론 설정 일치 필요

---

## 생성/수정된 주요 파일

| 파일 | 설명 |
|------|------|
| `src/data/aihub/extract_for_detector.py` | AIHub 데이터 추출 (bbox 로직 수정) |
| `src/data/cleanup_detector_data.py` | 데이터 정제 스크립트 |
| `src/models/yolo11m_detector.py` | Detector 학습 스크립트 |
| `src/models/convnext_classifier.py` | Classifier 학습 스크립트 |
| `src/inference/pill_pipeline_v2.py` | 2-Stage 파이프라인 |
| `src/inference/submit_v2.py` | Kaggle 제출용 추론 |

---

## 결론

2-Stage Pipeline과 AIHub 데이터 활용으로 Baseline 0.815에서 **0.96703**까지 개선 달성.
핵심은 Detector 학습 시 **모든 알약의 bbox를 포함**하도록 데이터 추출 로직을 수정한 것.
